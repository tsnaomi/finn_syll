# coding=utf-8

# standard library
import re

from datetime import datetime
from functools import wraps
from math import ceil

# installed
from tabulate import tabulate
from flask import (
    abort,
    flash,
    Flask,
    redirect,
    render_template,
    request,
    session,
    url_for,
    )
from flaskext.markdown import Markdown
from flask.ext.migrate import Migrate, MigrateCommand
from flask.ext.seasurf import SeaSurf
from flask.ext.sqlalchemy import SQLAlchemy
from flask.ext.script import Manager
from flask.ext.bcrypt import Bcrypt
from sqlalchemy import or_, and_
from sqlalchemy.exc import DataError
from sqlalchemy.ext.hybrid import hybrid_property
from werkzeug.exceptions import BadRequestKeyError

# local
from syllabifier import FinnSyll, phon

app = Flask(__name__, static_folder='_static', template_folder='_templates')
app.config.from_pyfile('config.py')

db = SQLAlchemy(app)
migrate = Migrate(app, db)
manager = Manager(app)
manager.add_command('db', MigrateCommand)

# To mirate database:
#     python app.py db migrate
#     python app.py db upgrade

csrf = SeaSurf(app)
flask_bcrypt = Bcrypt(app)
markdown = Markdown(app)


# Models ----------------------------------------------------------------------

class Linguist(db.Model):
    __tablename__ = 'Linguist'

    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(40), unique=True, nullable=False)
    password = db.Column(db.String(80), nullable=False)
    is_admin = db.Column(db.Boolean, default=False)

    def __init__(self, username, password):
        self.username = username
        self.password = flask_bcrypt.generate_password_hash(password)

    def __repr__(self):
        return self.username

    def __unicode__(self):
        return self.__repr__()

    def update_password(self, password):
        '''Update the linguist's password.'''
        self.password = flask_bcrypt.generate_password_hash(password)
        db.session.commit()


class Token(db.Model):
    __tablename__ = 'Token'

    id = db.Column(db.Integer, primary_key=True)

    # a boolean indicating if this word appears in the Aamulehti newspaper
    # corpus
    is_aamulehti = db.Column(db.Boolean, default=False)

    # a boolean indicating if this word appears in the Gutenberg poetry
    is_gutenberg = db.Column(db.Boolean, default=False)

    # the word's orthography -- if pulled from the Aamulehti-1999 coprus, it
    # preserves how the word was capitalized when we first encountered it;
    # if pulled from the Gutenberg poetry, it is lowercase
    orth = db.Column(db.String(80, convert_unicode=True), nullable=False)

    # the word's orthography in lowercase, with umlauts replaced and compound
    # boundaries delimited; generated by hand
    gold_base = db.Column(db.String(80, convert_unicode=True), nullable=True)

    # the word's orthography in lowercase, with umlauts replaced and compound
    # boundaries delimited; generated by the compound segmenter
    test_base = db.Column(db.String(80, convert_unicode=True), nullable=True)

    # the word's lemma/citation form -- nominative singular for nouns and first
    # infinitive for verbs (obtained from Aamulehti)
    lemma = db.Column(db.String(80, convert_unicode=True), default='')

    # an enum indicating whether the word is in the training, dev, or test set
    data = db.Column(db.Enum('train', 'dev', 'test', name='DATA'))

    # an integer indicating to which fold the word belongs in cross-validation
    fold = db.Column(db.Integer, default=0)

# rules applied in test syllabifications ----------------------------------

    rules1 = db.Column(db.String(80, convert_unicode=True), default='')

    rules2 = db.Column(db.String(80, convert_unicode=True), default='')

    rules3 = db.Column(db.String(80, convert_unicode=True), default='')

    rules4 = db.Column(db.String(80, convert_unicode=True), default='')

    rules5 = db.Column(db.String(80, convert_unicode=True), default='')

    rules6 = db.Column(db.String(80, convert_unicode=True), default='')

    rules7 = db.Column(db.String(80, convert_unicode=True), default='')

    rules8 = db.Column(db.String(80, convert_unicode=True), default='')

    rules9 = db.Column(db.String(80, convert_unicode=True), default='')

    rules10 = db.Column(db.String(80, convert_unicode=True), default='')

    rules11 = db.Column(db.String(80, convert_unicode=True), default='')

    rules12 = db.Column(db.String(80, convert_unicode=True), default='')

    rules13 = db.Column(db.String(80, convert_unicode=True), default='')

    rules14 = db.Column(db.String(80, convert_unicode=True), default='')

    rules15 = db.Column(db.String(80, convert_unicode=True), default='')

    rules16 = db.Column(db.String(80, convert_unicode=True), default='')

# test syllabifications ---------------------------------------------------

    test_syll1 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll2 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll3 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll4 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll5 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll6 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll7 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll8 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll9 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll10 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll11 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll12 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll13 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll14 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll15 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll16 = db.Column(db.String(80, convert_unicode=True), default='')

# correct syllabifications (hand-verified) --------------------------------

    syll1 = db.Column(db.String(80, convert_unicode=True), default='')

    syll2 = db.Column(db.String(80, convert_unicode=True), default='')

    syll3 = db.Column(db.String(80, convert_unicode=True), default='')

    syll4 = db.Column(db.String(80, convert_unicode=True), default='')

    syll5 = db.Column(db.String(80, convert_unicode=True), default='')

    syll6 = db.Column(db.String(80, convert_unicode=True), default='')

    syll7 = db.Column(db.String(80, convert_unicode=True), default='')

    syll8 = db.Column(db.String(80, convert_unicode=True), default='')

    syll9 = db.Column(db.String(80, convert_unicode=True), default='')

    syll10 = db.Column(db.String(80, convert_unicode=True), default='')

    syll11 = db.Column(db.String(80, convert_unicode=True), default='')

    syll12 = db.Column(db.String(80, convert_unicode=True), default='')

    syll13 = db.Column(db.String(80, convert_unicode=True), default='')

    syll14 = db.Column(db.String(80, convert_unicode=True), default='')

    syll15 = db.Column(db.String(80, convert_unicode=True), default='')

    syll16 = db.Column(db.String(80, convert_unicode=True), default='')

# -------------------------------------------------------------------------

    # the word's part-of-speech
    pos = db.Column(db.String(80, convert_unicode=True), default='')

    # the word's morpho-syntactic description
    msd = db.Column(db.String(80, convert_unicode=True), default='')

    # the word's frequency in the Aamulehti-1999 corpus
    freq = db.Column(db.Integer, default=0)

    # a boolean indicating if the word is marked as a compound by Arto
    is_compound = db.Column(db.Boolean, default=False)

    # a boolean indicating if the word is marked as a compound by an annotator
    is_complex = db.Column(db.Boolean, default=None)

    # a boolean indicating if the word is a stopword -- only if the word's
    # syllabification is lexically marked
    is_stopword = db.Column(db.Boolean, default=False)

    # a boolean indicating if the word is likely a non-nativized loanword;
    # detected with phon.is_foreign(phon.replace_umlauts(gold_base))
    is_loanword = db.Column(db.Boolean, default=False)

    # a boolean indicating if the syllabifier has correclt syllabified the word
    is_gold = db.Column(db.Boolean, default=None)

    # a note field to jot down notes about the word
    note = db.Column(db.Text, default='')

    # a temporary boolean to indicate whether Arto had verified the token prior
    # to updating the database to accommodate variation in test syllabifcations
    # (this is likely safe to delete now)
    verified = db.Column(db.Boolean, default=False)

    # a one-to-many relationship with the Variation table (many Variations per
    # one Token)
    variations = db.relationship(
        'Variation',
        backref='t_variation',
        lazy='dynamic',
        )

    # annotation helper attributes --------------------------------------------

    # a boolean indicating if the annotator requires context for the word
    needs_context = db.Column(db.Boolean, default=False)

    # an excerpt from the Aamulehti corpus containing the word
    context = db.Column(db.Text, default='')

    # -------------------------------------------------------------------------

    __mapper_args__ = {
        'order_by': [is_gold, is_complex, freq.desc()],
        }

    def __init__(self, orth, **kwargs):
        self.orth = orth

        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

        self.inform_base()
        self.detect_is_compound()
        self.syllabify()

    def __repr__(self):
        return self.orth

    def __unicode__(self):
        return self.__repr__()

    def readable_lemma(self):
        '''Return a readable form of the lemma.'''
        return self.lemma.replace('_', ' ')

    def is_lemma(self):
        '''Return True if the word is in its citation form, else False.'''
        return self.orth.lower() == self.readable_lemma().lower()

    # Syllabification methods -------------------------------------------------

    def split(self):
        '''Programmatically split Token.orth into constituent words.'''
        self.test_base = FinnSyll.split(self.orth.encode('utf-8'))

    def syllabify(self):  # 98.7048
        '''Programmatically syllabify Token.orth.'''
        word = self.orth.encode('utf-8')
        syllabifications = list(set(FinnSyll.syllabify(word)))  # fix set/rules

        n = 16 - len(syllabifications)
        syllabifications += [('', '') for i in range(n)]

        for i, (test_syll, rules) in enumerate(syllabifications, start=1):
            rules = rules.translate(None, 'abcdefg')

            setattr(self, 'test_syll' + str(i), test_syll.decode('utf-8'))
            setattr(self, 'rules' + str(i), rules)

        if self.syll1:
            self.update_gold()

    def update_gold(self):
        '''Token.is_gold is True iff there is perfect precision and recall.'''
        self.is_gold = self.sylls() == self.test_sylls()

    def test_sylls(self):
        '''Return a set of all of the Token's test syllabifications.'''
        test_sylls = [getattr(self, 'test_syll%s' % n) for n in range(1, 9)]
        test_sylls = set(filter(None, test_sylls))

        return test_sylls

    def sylls(self):
        '''Return a set of all of the Token's correct syllabifications.'''
        sylls = [getattr(self, 'syll%s' % n) for n in range(1, 9)]
        sylls = set(filter(None, sylls))

        return sylls

    def correct(self, **kwargs):
        '''Save new attributes to the Token and update its gold status.'''
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

        self.update_gold()

    # Compound properties -----------------------------------------------------

    @hybrid_property
    def is_split(self):
        '''A boolean indicating if the Token is predicted to be a compound.'''
        return '=' in self.test_base

    @is_split.expression
    def is_split(cls):
        '''A boolean indicating if the Token is predicted to be a compound.'''
        return cls.test_base.contains('=')

    # Variation properties ----------------------------------------------------

    @hybrid_property
    def is_ambiguous(self):
        '''A boolean indicating if the Token perhaps exhibits variation.'''
        return bool(self.test_syll2 or self.syll2)

    @is_ambiguous.expression
    def is_ambiguous(cls):
        '''A boolean indicating if the Token perhaps exhibits variation.'''
        return or_(cls.test_syll2 != '', cls.syll2 != '')

    # Evaluation properties ---------------------------------------------------

    @property
    def p_r(self):
        '''A string repr of the Token's precision and recall (P / R).'''
        return '%s / %s' % (round(self.precision, 2), round(self.recall, 2))

    @property
    def precision(self):
        '''See https://en.wikipedia.org/wiki/Precision_and_recall#Precision.'''
        try:
            return round(
                len(self.test_sylls().intersection(self.sylls())) * 1.0 /
                len(self.test_sylls()),
                2)

        except ZeroDivisionError:
            return 0.0

    @property
    def recall(self):
        '''See https://en.wikipedia.org/wiki/Precision_and_recall#Recall.'''
        try:
            return round(
                len(self.test_sylls().intersection(self.sylls())) * 1.0 /
                len(self.sylls()),
                2)

        except ZeroDivisionError:
            return 0.0

    @property
    def f1(self):
        '''See https://en.wikipedia.org/wiki/F1_score.'''
        p = self.precision
        r = self.recall

        try:
            return 2.0 * (p * r) / (p + r)

        except ZeroDivisionError:
            return 0.0


class Poem(db.Model):
    __tablename__ = 'Poem'

    id = db.Column(db.Integer, primary_key=True)

    # the title of the poem
    title = db.Column(db.String(80, convert_unicode=True), default='')

    # the name of the poet
    poet = db.Column(db.Enum(
        u'Erkko',        # J. H. Erkko
        u'Hellaakoski',  # Aaro Hellaakoski
        u'Kaatra',       # Kössi Kaatra
        u'Kailas',       # Uuno Kailas
        u'Koskenniemi',  # V. A. Koskenniemi
        u'Kramsu',       # Kaarlo Kramsu
        u'Leino',        # Eino Leino
        u'Lönnrot',      # Elias Lönnrot
        u'Siljo',        # Juhani Siljo
        name='POET',
        convert_unicode=True,
        ))

    # each book of poetry is split into portions of roughly 1600 lines,
    # manually spread across several Poem objects
    portion = db.Column(db.Integer, default=1)

    # the poem's Gutenberg ebook number
    ebook_number = db.Column(db.Integer)

    # the poem's release date
    date_released = db.Column(db.DateTime)

    # the date the poem was last updated on Gutenberg, if different from the
    # the relase date
    last_updated = db.Column(db.DateTime)

    # the poem as a tokenized lists, incl. Variation IDs and strings of words
    tokenized_poem = db.Column(db.PickleType)

    # a boolean indicating if all of the poem's variations have been reviewed
    reviewed = db.Column(db.Boolean, default=False)

    # a one-to-many relationship with the Variation table (many Variations per
    # Poem)
    variations = db.relationship(
        'Variation',
        backref='p_variation',
        lazy='dynamic',
        )

    # the number of sequences associated with this poetry ebook
    sequence_count = db.Column(db.Integer)

    # a boolean indicating if review has begun for this poem
    review_begun = db.Column(db.Boolean, default=False)

    def __init__(self, **kwargs):
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return '%s by %s' % (self.title, self.poet)

    def __unicode__(self):
        return self.__repr__()

    @property
    def ebook(self):
        '''The poem/book of poems' Gutenberg identifier.'''
        return 'EBook #%s' % self.ebook_number

    @property
    def poet_surname(self):
        '''Return the poet's surname.'''
        return self.poet.split()[-1]

    def query_poem(self):
        '''Return a list of Variations and words as they appear in the poem.'''
        variations = {v.id: v for v in self.variations}
        poem = [variations.get(w, w) for w in self.tokenized_poem]

        return poem

    def update_review(self):
        '''Set reviewed to True if all of the variations have been verified.'''
        reviewed = all(variation.verified for variation in self.variations)
        self.reviewed = reviewed

    def get_sequence_count(self):
        '''Return a formatted sequence count.'''
        return format(self.sequence_count, ',d')

    def get_sequences(self):
        ''' '''
        return [s for v in self.variations for s in v.sequences]


class Variation(db.Model):
    __tablename__ = 'Variation'

    id = db.Column(db.Integer, primary_key=True)

    # a one-to-many relationship with the Token table (many Variations per
    # Token)
    token_id = db.Column(db.Integer, db.ForeignKey('Token.id'))

    # a one-to-many relationship with the Poem table (many Variations per
    # Poem)
    poem_id = db.Column(db.Integer, db.ForeignKey('Poem.id'))

    # a one-to-many relationship with the Sequence table (many Sequences per
    # Variation)
    sequences = db.relationship(
        'Sequence',
        backref='v_sequence',
        lazy='dynamic',
        )

    def __init__(self, token, poem):
        self.token_id = token
        self.poem_id = poem

    def __repr__(self):
        return 'Variation %s' % self.id

    def __unicode__(self):
        return self.__repr__()

    @property
    def verified(self):
        '''A boolean indicating if this Variation has been hand-verified.'''
        return all(seq.verified for seq in self.sequences)

    def display(self):
        '''A string represenation of this Variation.'''
        return self.t_variation.orth.lower()

    def get_sequences(self):
        '''Return a list of related Sequence objects.'''
        return [seq for seq in self.sequences]


class Sequence(db.Model):
    __tablename__ = 'Sequence'

    id = db.Column(db.Integer, primary_key=True)

    # a one-to-many relationship with the Variation table (many Sequences per
    # one Variation)
    variation_id = db.Column(db.Integer, db.ForeignKey('Variation.id'))

    # the sequence of vowels under consideration
    sequence = db.Column(db.String(10, convert_unicode=True), default='')

    # the html representation of the related token, highlighting the sequence
    html = db.Column(db.String(80, convert_unicode=True), default='')

    # # the starting index of the vowel sequence in the token
    # index = db.Column(db.Integer)

    # # the right environment of the vowel sequence
    # right = db.Column(db.Enum(
    #     '#', 'V', 'CV', 'CC+V', 'C+#',
    #     name='RIGHT',
    #     ))

    # an enum indicating if this sequence splits or joins
    split = db.Column(db.Enum('split', 'join', 'unknown', name='SPLIT'))

    # the scansion or metric precision of this sequence:
    # S - strong, W - weak, UNK - unknown
    scansion = db.Column(db.Enum(
        'S', 'W', 'SW', 'WS', 'SS', 'WW', 'UNK',
        name='SCANSION',
        ))

    # a boolean indicating if the sequence begins in an odd syllable
    is_odd = db.Column(db.Boolean, default=None)

    # a note field to jot down notes about this sequence
    note = db.Column(db.Text, default='')

    def __init__(self, variation, sequence, **kwargs):
        self.variation_id = variation
        self.sequence = sequence

        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return self.html.replace('<br>', '{').replace('</br>', '}')

    def __unicode__(self):
        return self.__repr__()

    @hybrid_property
    def verified(self):
        '''A boolean indicating if this Sequence has been hand-verified.'''
        return bool(self.split and self.scansion)

    @verified.expression
    def verified(cls):
        '''A boolean indicating if this Sequence has been hand-verified.'''
        return and_(cls.split.isnot(None), cls.scansion.isnot(None))

    def correct(self, split=None, scansion=None, note=''):
        '''Save new attributes to the Sequence.'''
        self.split = split
        self.scansion = scansion
        self.note = note

    def update_is_odd(self):
        '''Populate Sequence.is_odd.'''
        test_syll = self.v_sequence.t_variation.test_syll1
        start = self.html.find('<')
        dots = [1 for i, j in enumerate(test_syll) if i <= start and j == '.']
        is_odd = sum(dots) % 2 == 0

        self.is_odd = is_odd

    def is_word_initial(self):
        ''''''
        vowels = [u'i', u'e', u'ä', u'y', u'ö', u'a', u'u', u'o']
        i = self.html.find('<')
        is_word_initial = not any(v in vowels for v in self.html[:i])

        return is_word_initial

    def is_word_final(self):
        ''''''
        vowels = [u'i', u'e', u'ä', u'y', u'ö', u'a', u'u', u'o']
        i = self.html.rfind('>')
        is_word_final = not any(v in vowels for v in self.html[i:])

        return is_word_final

    def is_heavy(self):
        ''''''
        vowels = [u'i', u'e', u'ä', u'y', u'ö', u'a', u'u', u'o']
        i = self.html.rfind('>')

        if self.is_word_final():
            return i != len(self.html) - 1

        return self.html[i + 2] not in vowels


class Document(db.Model):
    __tablename__ = 'Document'

    id = db.Column(db.Integer, primary_key=True)

    # the name of the xml file in the Aamulehti-1999 corpus
    filename = db.Column(db.Text, unique=True)

    # a boolean indicating if all of the document's words have been reviewed
    reviewed = db.Column(db.Boolean, default=False)

    # the text as a tokenized list, incl. Token IDs and punctuation strings
    tokenized_text = db.Column(db.PickleType)

    # a list of IDs for each word as they appear in the text
    tokens = db.Column(db.PickleType)

    # number of unique Tokens that appear in the text
    unique_count = db.Column(db.Integer)

    def __init__(self, filename, tokenized_text, tokens):
        self.filename = filename
        self.tokenized_text = tokenized_text
        self.tokens = tokens
        self.unique_count = len(tokens)

    def __repr__(self):
        return self.filename

    def __unicode__(self):
        return self.__repr__()

    def query_document(self):
        '''Return a list of Tokens and puncts as they appear in the text.'''
        tokens = {t.id: t for t in self.get_tokens()}
        doc = [tokens.get(t, t) for t in self.tokenized_text]

        return doc

    def get_tokens(self):
        '''Return a list of the Tokens that appear in the text.'''
        return db.session.query(Token).filter(Token.id.in_(self.tokens)).all()

    def verify_all_unverified_tokens(self):
        '''For all of the text's unverified Tokens, set syll equal to test_syll.

        This function is intended for when all uverified Tokens have been
        correctly syllabified in test_syll. Proceed with caution.
        '''
        tokens = self.get_tokens()

        for token in tokens:
            if token.is_gold is None:
                token.correct(syll=token.test_syll)

        self.reviewed = True
        db.session.commit()

    def update_review(self):
        '''Set reviewed to True if all of the Tokens have been verified.'''
        tokens = self.get_tokens()
        unverified_count = 0

        for t in tokens:
            if t.is_gold is None:
                unverified_count += 1
                break

        # if there are no unverified tokens but the document isn't marked as
        # reviewed, mark the document as reviewed; this would be the case if
        # all of the documents's tokens were verified in previous documents
        if unverified_count == 0:
            self.reviewed = True


class Performance(db.Model):
    __tablename__ = 'Performance'
    id = db.Column(db.Integer, primary_key=True)
    with_loanwords = db.Column(db.Boolean, default=False)
    p = db.Column(db.Float)
    r = db.Column(db.Float)
    f1 = db.Column(db.Float)
    total = db.Column(db.Integer)
    verified = db.Column(db.Integer)
    correct = db.Column(db.Integer)
    simp_verified = db.Column(db.Integer)
    simp_correct = db.Column(db.Integer)
    comp_verified = db.Column(db.Integer)
    comp_correct = db.Column(db.Integer)

    def __init__(self,  **kwargs):
        self.total = 991730  # Token.query.filter_by(is_aamulehti=True).count()
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return '%s/%s (%s)' % (self.p, self.r, self.acc)

    def __unicode__(self):
        return self.__repr__()

    @property
    def acc(self):
        '''Return total accuracy.'''
        return (float(self.correct) / self.verified) * 100

    @property
    def simplex_acc(self):
        '''Return simplex accuracy.'''
        return (float(self.simp_correct) / self.simp_verified) * 100

    @property
    def complex_acc(self):
        '''Return complex accuracy.'''
        return (float(self.comp_correct) / self.comp_verified) * 100


# Database functions ----------------------------------------------------------

def find_token(orth):
    '''Retrieve a token by its orthography.'''
    try:
        # ilike queries are case insensitive
        token = Token.query.filter(Token.orth.ilike(orth)).first()
        return token

    except KeyError:
        return None


def adjust(func):
    '''Adjust tokens by applying func to each token.'''
    count = Token.query.count()
    start = 0
    end = x = 1000

    while start + x < count:
        for token in Token.query.order_by(Token.id).slice(start, end):
            func(token)

        db.session.commit()
        start = end
        end += x

    for token in Token.query.order_by(Token.id).slice(start, count):
        func(token)

    db.session.commit()


@manager.command
def split_compounds():
    '''Split all tokens.'''
    print 'Splitting compounds... ' + datetime.utcnow().strftime('%I:%M')

    adjust(func=lambda t: t.split())

    print 'Splitting complete. ' + datetime.utcnow().strftime('%I:%M')


@manager.command
def syllabify_tokens():
    '''Syllabify all tokens.'''
    print 'Syllabifying... ' + datetime.utcnow().strftime('%I:%M')

    adjust(func=lambda t: t.syllabify())

    print 'Syllabifications complete. ' + datetime.utcnow().strftime('%I:%M')

    # calculate average precision, recall, f1, and accuracy
    update_performance()


@manager.command
def update_poems():
    '''Update the reviewed status of each Poem object.'''
    for poem in Poem.query.all():
        poem.update_review()

    db.session.commit()


@manager.command
def update_performance():
    '''Calculate average precision, recall, f1, and accuracy.'''
    for with_loanwords in (True, False):
        P = Performance.query.filter_by(with_loanwords=with_loanwords).first()

        calculate = lambda t: round(float(sum(t)) / P.verified, 4)

        verified_tokens = get_gold_tokens()

        if not with_loanwords:
            verified_tokens = verified_tokens.filter_by(is_loanword=False)

        correct_tokens = verified_tokens.filter_by(is_gold=True)

        P.verified = verified_tokens.count()
        P.correct = correct_tokens.count()

        P.simp_verified = verified_tokens.filter_by(is_complex=False).count()
        P.simp_correct = correct_tokens.filter_by(is_complex=False).count()

        P.comp_verified = verified_tokens.filter_by(is_complex=True).count()
        P.comp_correct = correct_tokens.filter_by(is_complex=True).count()

        P.p = calculate([t.precision for t in verified_tokens])
        P.r = calculate([t.recall for t in verified_tokens])
        P.f1 = calculate([t.f1 for t in verified_tokens])

    db.session.commit()


# Datasets --------------------------------------------------------------------

def training_set():
    '''Return training tokens.'''
    return Token.query.filter_by(data='train')


def dev_set():
    '''Return development/validation tokens.'''
    return Token.query.filter_by(data='dev')


def test_set():
    '''Return test/evaluation tokens.'''
    return Token.query.filter_by(data='test')


def full_training_set():
    '''Return training and validation tokens.'''
    return Token.query.filter(or_(Token.data == 'train', Token.data == 'dev'))


def training_test_set():
    '''Returning training and test tokens.'''
    return Token.query.filter(or_(Token.data == 'train', Token.data == 'test'))


def all_data():
    '''Return training, validation, and test tokens.'''
    return Token.query.filter(Token.data.isnot(None))


def get_fold(fold):
    '''Return all of the training/test tokens in the designated fold.'''
    return all_data().filter_by(fold=fold)


def exclude_fold(fold):
    '''Return all training/test tokens except those in the designated fold.'''
    return all_data().filter(Token.fold != fold)


# Basic queries ---------------------------------------------------------------

def get_gold_tokens(tokens=Token.query):
    '''Return all verified tokens -- good or bad.'''
    return tokens.filter(Token.is_gold.isnot(None))


def get_bad_tokens():
    '''Return all of the tokens that are incorrectly syllabified.'''
    return Token.query.filter_by(is_gold=False)


def get_good_tokens():
    '''Return all of the tokens that are correctly syllabified.'''
    return Token.query.filter_by(is_gold=True).order_by(Token.lemma)


def get_unverified_tokens():
    '''Return tokens with uncertain syllabifications.'''
    return Token.query.filter_by(is_aamulehti=True, is_gold=None)


def get_notes():
    '''Return all of the tokens that contain notes.'''
    return Token.query.filter(Token.note != '').order_by(Token.freq.desc())


def get_variation():
    '''Return tokens with alternative test or gold syllabifications.'''
    return Token.query.filter_by(is_aamulehti=True).filter(Token.is_ambiguous)


# Compound queries ------------------------------------------------------------

def get_test_compounds():
    '''Return tokens predicted to be compounds.'''
    return Token.query.filter(Token.is_split)


def get_gold_compounds():
    '''Return known compounds.'''
    return Token.query.filter_by(is_complex=True)


def get_FN_compounds():  # TODO
    '''Return hand-verified compounds that are not predicted compounds.'''
    tokens = Token.query.filter_by(is_complex=True)
    tokens = tokens.filter(Token.is_split.isnot(False))

    return tokens


def get_FP_compounds():  # TODO
    '''Return predicted compounds that are not true compounds.'''
    return Token.query.filter_by(is_complex=False).filter(Token.is_split)


# View helpers ----------------------------------------------------------------

@app.before_request
def renew_session():
    # Forgot why I did this... but I think it's important
    session.modified = True


def login_required(x):
    # View decorator requiring users to be authenticated to access the view
    @wraps(x)
    def decorator(*args, **kwargs):
        if session.get('current_user'):

            if session.get('is_admin'):
                return x(*args, **kwargs)

            if x.func_name == 'main_view':
                return redirect(url_for('annotation_view'))

            abort(404)

        return redirect(url_for('login_view'))

    return decorator


# @app.context_processor
def serve_docs():
    # Serve Aamulehti documents to all views
    docs = Document.query.filter_by(reviewed=False)
    docs = docs.order_by(Document.unique_count).limit(10)

    return dict(docs=docs)


def apply_form(http_form, commit=True):
    # Apply changes to Token instance based on POST request
    try:
        token = Token.query.get(http_form['id'])
        syll1 = http_form['syll1']
        syll2 = http_form.get('syll2', '')
        syll3 = http_form.get('syll3', '')
        syll4 = http_form.get('syll4', '')
        # syll5 = http_form.get('syll5', '')
        # syll6 = http_form.get('syll6', '')
        # syll7 = http_form.get('syll7', '')
        # syll8 = http_form.get('syll8', '')
        note = http_form.get('note', '')

        try:
            is_compound = bool(http_form.getlist('is_compound'))
            # is_stopword = bool(http_form.getlist('is_stopword'))

        except AttributeError:
            is_compound = bool(http_form.get('is_compound'))
            # is_stopword = bool(http_form.get('is_stopword'))

        token.correct(
            syll1=syll1,
            syll2=syll2,
            syll3=syll3,
            syll4=syll4,
            # syll5=syll5,
            # syll6=syll6,
            # syll7=syll7,
            # syll8=syll8,
            is_compound=is_compound,
            # is_stopword=is_stopword,
            note=note,
            verified_again=True,
            )

        if commit:
            db.session.commit()

    except (AttributeError, KeyError, LookupError):
        pass


def apply_bulk_form(http_form):
    # Apply changes to multiple Token instances based on POST request
    forms = {k: {} for k in range(1, 41)}
    attrs = ['id', 'syll1', 'syll2', 'syll3', 'syll4', 'is_compound', 'note']

    for i in range(1, 41):
        for attr in attrs:
            try:
                forms[i][attr] = http_form['%s_%s' % (attr, i)]

            except BadRequestKeyError:
                pass

    for form in forms.itervalues():
        apply_form(form, commit=False)

    db.session.commit()


def apply_sequence_form(http_form):
    # Apply changes to multiple Sequence instances based on POST request
    n = 2 if http_form.get('id_2') else 1
    forms = {k: {} for k in range(1, n + 1)}
    attrs = ['id', 'split', 'scansion', 'note']

    for i in range(1, n + 1):
        for attr in attrs:
            try:
                forms[i][attr] = http_form.get('%s_%s' % (attr, i))

            except BadRequestKeyError:
                pass

    for form in forms.itervalues():
        seq = Sequence.query.get(form['id'])
        seq.correct(
            split=form['split'],
            scansion=form['scansion'],
            note=form['note'],
            )

    db.session.commit()


# Views -----------------------------------------------------------------------

@app.route('/', methods=['GET', 'POST'])
@login_required
def main_view():  # TODO
    '''List statistics on the syllabifier's performance.'''
    P1 = Performance.query.filter_by(with_loanwords=False).first()
    P2 = Performance.query.filter_by(with_loanwords=True).first()

    return render_template('main.html', kw='main', P1=P1, P2=P2)


@app.route('/rules', methods=['GET', ])
@login_required
def rules_view():
    '''List syllabification rules.'''
    return render_template('rules.html', kw='rules')


@app.route('/notes', defaults={'page': 1}, methods=['GET', 'POST'])
@app.route('/notes/page/<int:page>', methods=['GET', 'POST'])
@login_required
def notes_view(page):
    '''List all tokens that contain notes.'''
    if request.method == 'POST':
        apply_form(request.form)

    tokens = get_notes()

    return render_template(
        'tokens.html',
        tokens=tokens,
        kw='notes',
        )


@app.route('/doc/<id>', methods=['GET', 'POST'])
@login_required
def doc_view(id):
    '''Present detail view of specified doc, composed of editable Tokens.'''
    if request.method == 'POST':
        apply_form(request.form)

    doc = Document.query.get_or_404(id)
    TEXT = doc.query_document()

    scroll = request.form.get('scroll', None)

    return render_template(
        'doc.html',
        doc=doc,
        TEXT=TEXT,
        kw='doc',
        scroll=scroll,
        )


@app.route('/approve/approve/approve/doc/<id>', methods=['POST', ])
@login_required
def approve_doc_view(id):
    '''For all of the doc's unverified Tokens, set syll equal to test_syll.'''
    doc = Document.query.get_or_404(id)
    doc.verify_all_unverified_tokens()

    return redirect(url_for('doc_view', id=id))


@app.route('/contains', methods=['GET', 'POST'])
@login_required
def contains_view():
    '''Search for tokens by word and/or citation form.'''
    results, find, count = None, None, None

    if request.method == 'POST':
        find = request.form.get('search')

        if request.form.get('syll1'):
            apply_form(request.form)

        if '.' in find:
            results = Token.query.filter_by(is_aamulehti=True).filter(or_(
                Token.test_syll1.contains(find),
                Token.test_syll2.contains(find),
                Token.test_syll3.contains(find),
                Token.test_syll4.contains(find),
                ))

        else:
            results = Token.query.filter(Token.orth.contains(find))

        count = format(results.count(), ',d')

        try:
            results = results[:500]

        except IndexError:
            pass

    return render_template(
        'search.html',
        kw='contains',
        results=results,
        find=find,
        count=count,
        )


@app.route('/find', methods=['GET', 'POST'])
@login_required
def find_view():
    '''Search for tokens by word and/or citation form.'''
    results, find = None, None

    if request.method == 'POST':

        if request.form.get('syll1'):
            apply_form(request.form)

        find = request.form.get('search') or request.form['syll1']
        FIND = find.strip().translate({ord('.'): None, })  # strip periods
        # FIND = find.strip().translate(None, '.')  # strip periods
        results = Token.query.filter(Token.orth.ilike(FIND))
        results = results.filter_by(is_aamulehti=True)
        results = results if results.count() > 0 else None

    return render_template(
        'search.html',
        kw='find',
        results=results,
        find=find,
        )


@app.route('/<kw>', defaults={'page': 1}, methods=['GET', 'POST'])
@app.route('/<kw>/page/<int:page>', methods=['GET', 'POST'])
@login_required
def token_view(kw, page):
    '''List all keyword-relevant Tokens and process corrections.'''
    if request.method == 'POST':
        apply_form(request.form)

    if kw == 'bad':
        # excludes non-nativized words and errors caused by the
        # compound segmenter
        tokens = (
            get_bad_tokens()
            .filter_by(is_loanword=False)
            .filter(Token.test_base == Token.gold_base)
            )

    elif kw == 'unverified':
        tokens = get_unverified_tokens(),

    else:
        abort(404)

    count = format(tokens.count(), ',d')
    tokens, pagination = paginate(page, tokens)

    return render_template(
        'tokens.html',
        tokens=tokens,
        kw=kw,
        pagination=pagination,
        count=count,
        description=True,
        )


@app.route('/unverified', defaults={'page': 1}, methods=['GET', 'POST'])
@app.route('/unverified/page/<int:page>', methods=['GET', 'POST'])
@login_required
def unverified_view(page):
    '''List all unverified Tokens and process corrections.'''
    if request.method == 'POST':
        apply_bulk_form(request.form)

    tokens = get_unverified_tokens().slice(0, 200)
    tokens, pagination = paginate(page, tokens, per_page=10)

    return render_template(
        'tokens.html',
        tokens=tokens,
        kw='unverified',
        pagination=pagination,
        )


@app.route('/lemmas', defaults={'page': 1}, methods=['GET', 'POST'])
@app.route('/lemmas/page/<int:page>', methods=['GET', 'POST'])
@login_required
def lemma_view(page):
    '''List all unverified unseen lemmas and process corrections.'''
    if request.method == 'POST':
        apply_bulk_form(request.form)

    tokens = get_unseen_lemmas()
    tokens, pagination = paginate(page, tokens)

    return render_template(
        'tokens.html',
        tokens=tokens,
        kw='lemmas',
        pagination=pagination,
        )


@app.route('/enter', methods=['GET', 'POST'])
def login_view():
    '''Sign in current user.'''
    if session.get('current_user'):
        return redirect(url_for('main_view'))

    if request.method == 'POST':
        username = request.form['username']
        linguist = Linguist.query.filter_by(username=username).first()

        if linguist is None or not flask_bcrypt.check_password_hash(
                linguist.password,
                request.form['password']
                ):
            flash('Invalid username and/or password.')

        else:
            session['current_user'] = linguist.username
            session['is_admin'] = linguist.is_admin
            return redirect(url_for('main_view'))

    return render_template('enter.html')


@app.route('/leave')
def logout_view():
    '''Sign out current user.'''
    session.pop('current_user', None)
    session.pop('is_admin', None)

    return redirect(url_for('main_view'))


# Annotation ------------------------------------------------------------------

def get_needs_context():
    '''Return tokens that require context.'''
    return Token.query.filter(Token.context != '')


def get_needs_annotation():
    '''Return tokens that require annotating.'''
    return get_gold_tokens().filter_by(is_complex=None, needs_context=False)


@app.route('/annotation', defaults={'page': 1}, methods=['GET', 'POST'])
@app.route('/annotation/page/<int:page>', methods=['GET', 'POST'])
def annotation_view(page):
    '''Facilitate compound annotations.'''
    if not session.get('current_user'):
        return redirect(url_for('login_view'))

    errors = []

    if request.method == 'POST':

        for k, v in request.form.iteritems():

            if k.startswith('id'):
                token = Token.query.get(int(v))
                orth = token.orth.lower()
                base = request.form.get('base_%s' % v).lower()
                unsure = bool(request.form.getlist('unsure_%s' % v))

                if unsure:
                    token.needs_context = unsure
                    token.gold_base = base

                elif validate_annotation(orth, base):
                    token.is_complex = orth != base
                    token.gold_base = phon.replace_umlauts(base)

                else:
                    errors.append(base)
                    token.gold_base = base

        db.session.commit()

    tokens = get_needs_annotation()
    count = format(tokens.count(), ',d')

    return render_template(
        'annotation.html',
        tokens=tokens.slice(0, 25),
        count=count,
        kw='annotation',
        errors=',  '.join(errors),
        )


@app.route('/needs-context', defaults={'page': 1}, methods=['GET', 'POST'])
@app.route('/needs-context/page/<int:page>', methods=['GET', 'POST'])
def needs_context_view(page):
    '''Facilitate compound annotations for words that need context.'''
    if not session.get('current_user'):
        return redirect(url_for('login_view'))

    errors = None

    if request.method == 'POST':
        token = Token.query.get(int(request.form.get('id')))
        orth = token.orth.lower()
        base = request.form.get('base').lower()

        if validate_annotation(orth, base):
            token.is_complex = orth != base
            token.gold_base = phon.replace_umlauts(base)
            token.needs_context = False

        else:
            errors = base
            token.gold_base = base

        db.session.commit()

    tokens = Token.query.filter_by(needs_context=True)
    count = format(tokens.count(), ',d')

    return render_template(
        'annotation.html',
        tokens=tokens,
        count=count,
        kw='needs-context',
        errors=errors,
        )


def validate_annotation(orth, base):
    '''Validate an annotated base.'''
    if orth == base:
        return True

    if orth == base.translate({ord('='): None, }):
        for part in re.split(r'(-| )', base):
            if part.startswith('=') or part.endswith('='):
                return False

        return True

    return False


# Poems -----------------------------------------------------------------------

def get_sequence_tables(query=Sequence.query.filter_by(verified=True)):
    '''Generate table on Sequence statistics.'''
    sequences1 = []
    sequences2 = []
    sequences3 = []
    sequences4 = []

    headers1 = ['', 'total', 'joined', 'split', 'unsure']       # all table
    headers2 = ['', 'total', 'S', 'W', 'unsure']                # joined
    headers3 = ['', 'total', 'S', 'W', 'SW', 'WS', 'unsure']    # split
    headers4 = ['', 'total', 'S', 'W', 'unsure']                # unsure

    diphthongs = ['', 'iu', 'iy', 'eu', 'ey', 'au', 'äy', 'ou', 'öy']

    f = lambda n, t: '%s %s' % (
        str(n),
        '(' + str(round((float(n) / t) * 100.0, 2)) + '%)' if n else '',
        )

    for vv in diphthongs:

        if vv:
            seqs = query.filter_by(sequence=vv).distinct()

        else:
            seqs = query.distinct()
            vv = '<i>all</i>'

        total = seqs.count()
        _join = seqs.filter_by(split='join')
        join = _join.count()
        join_s = _join.filter_by(scansion='S').count()
        join_w = _join.filter_by(scansion='W').count()
        join_unk = join - join_s - join_w
        _split = seqs.filter_by(split='split')
        split = _split.count()
        split_s = _split.filter_by(scansion='S').count()
        split_w = _split.filter_by(scansion='W').count()
        split_sw = _split.filter_by(scansion='SW').count()
        split_ws = _split.filter_by(scansion='WS').count()
        split_unk = split - split_s - split_w - split_sw - split_ws
        _unknown = seqs.filter_by(split='unknown')
        unknown = unknown = total - split - join
        unknown_s = _unknown.filter_by(scansion='S').count()
        unknown_w = _unknown.filter_by(scansion='W').count()
        unknown_unk = unknown - unknown_s - unknown_w

        sequences1.append([
            '<strong>' + vv.decode('utf-8') + '</strong>',
            total,
            f(join, total),
            f(split, total),
            f(unknown, total),
            ])

        sequences2.append([
            '<strong>' + vv.decode('utf-8') + '</strong>',
            join,
            f(join_s, join),
            f(join_w, join),
            f(join_unk, join),
            ])

        sequences3.append([
            '<strong>' + vv.decode('utf-8') + '</strong>',
            split,
            f(split_s, split),
            f(split_w, split),
            f(split_sw, split),
            f(split_ws, split),
            f(split_unk, split),
            ])

        sequences4.append([
            '<strong>' + vv.decode('utf-8') + '</strong>',
            unknown,
            f(unknown_s, unknown),
            f(unknown_w, unknown),
            f(unknown_unk, unknown),
            ])

    table1 = tabulate(sequences1, headers1, tablefmt='html')
    table2 = tabulate(sequences2, headers2, tablefmt='html')
    table3 = tabulate(sequences3, headers3, tablefmt='html')
    table4 = tabulate(sequences4, headers4, tablefmt='html')

    return table1, table2, table3, table4


@app.route('/poems', methods=['GET', ])
@login_required
def poems_view():
    '''Present an index of poems.'''
    poems = Poem.query.order_by(
        Poem.poet,
        Poem.ebook_number,
        Poem.portion,
        ).all()

    return render_template('poems.html', poems=poems, kw='poems')


@app.route('/poems/<id>', methods=['GET', 'POST'])
@login_required
def poem_view(id):
    '''Present detail view of specified doc, composed of editable Tokens.'''
    poem = Poem.query.get_or_404(id)
    POEM = poem.query_poem()

    if request.method == 'POST':
        poem.review_begun = True
        apply_sequence_form(request.form)

    return render_template('poem.html', poem=poem, POEM=POEM, kw='poem')


@app.route('/poems/update', methods=['GET', ])
@login_required
def poem_update_view():
    '''Call update_poems().'''
    update_poems()

    return redirect(url_for('poem_view', id=1))


@app.route('/poems/numbers', methods=['GET', ])
@app.route('/poems/<poet>-numbers', methods=['GET', ])
def poem_numbers_view(poet=None):
    if poet:

        try:
            query = Sequence.query.join(Variation).join(Poem)
            query = query.filter(Poem.poet == poet)
            query = query.outerjoin(Sequence).filter_by(verified=True)
            table1, table2, table3, table4 = get_sequence_tables(query=query)

        except DataError:
            abort(404)

    else:
        table1, table2, table3, table4 = get_sequence_tables()

    return render_template(
        'sequence.html',
        table1=table1,
        table2=table2,
        table3=table3,
        table4=table4,
        poet=poet or 'all',
        kw='poem-numbers',
        )


# Jinja2 ----------------------------------------------------------------------

def stat(n):
    if int(n) == float(n):
        return '{:,}'.format(n)

    if n < 1.0:
        return '{:.4f}'.format(n)

    return '{:.2f}'.format(n)


def goldclass(t):
    gold = t.is_gold
    gold = u'good' if gold else u'unverified' if gold is None else u'bad'
    compound = ' compound' if t.is_complex else ''

    return gold + compound


def variationclass(v):
    return 'variation-verified' if v.verified else 'variation-unverified'


def js_safe(s):
    s = s.replace('\r\n', '&#13;&#10;')
    s = s.replace('(', '&#40;').replace(')', '&#41;')
    s = s.replace('"', '&#34;').replace("'", '&#34;')

    return s

app.jinja_env.filters['stat'] = stat
app.jinja_env.filters['goldclass'] = goldclass
app.jinja_env.filters['variationclass'] = variationclass
app.jinja_env.filters['js_safe'] = js_safe
app.jinja_env.tests['token'] = lambda t: hasattr(t, 'syll1')
app.jinja_env.tests['variation'] = lambda v: hasattr(v, 'sequences')


# Pagination ------------------------------------------------------------------

class Pagination(object):

    def __init__(self, page, per_page, total_count):
        self.page = page
        self.per_page = per_page
        self.total_count = total_count

    @property
    def pages(self):
        return int(ceil(self.total_count / float(self.per_page)))

    @property
    def has_prev(self):
        return self.page > 1

    @property
    def has_next(self):
        return self.page < self.pages

    def iter_pages(self):
        left_edge, left_current = 2, 2
        right_edge, right_current = 2, 5

        last = 0
        for num in xrange(1, self.pages + 1):

            if num <= left_edge or (
                num > self.page - left_current - 1 and
                num < self.page + right_current
                    ) or num > self.pages - right_edge:

                if last + 1 != num:
                    yield None

                yield num

                last = num


def paginate(page, tokens, per_page=40):
    count = tokens.count()
    start = (page - 1) * per_page or 0
    end = min(start + per_page, count)

    try:
        tokens = tokens[start:end]

    except IndexError:
        if page != 1:
            abort(404)

    pagination = Pagination(page, per_page, count)

    return tokens, pagination


def url_for_other_page(page):
    args = request.view_args.copy()
    args['page'] = page

    return url_for(request.endpoint, **args)

app.jinja_env.globals['url_for_other_page'] = url_for_other_page


# Compound statistics ---------------------------------------------------------

class CompoundNumbers(object):

    def __init__(self):
        self.table = []
        self.data = [
            ('Training', training_set()),
            ('Validation', dev_set()),
            ('Test', test_set()),
            ('Training + Validation', full_training_set()),
            ('All', all_data()),
        ]

        for label, data in self.data:
            self.table.append(self.count(label, data))
            label += ' (excl. loans)'
            data = data.filter_by(is_loanword=False)
            self.table.append(self.count(label, data))

        self.table = tabulate(self.table, headers=[
            'Data set', 'Total', 'Simplex', 'Complex', 'Open', 'Closed',
            ])

        print self.table

    def count(self, label, data):
        numbers = []

        numbers.append(label)

        # all tokens
        total = data.count()
        numbers.append(total)

        # simplex tokens
        simplex = data.filter_by(is_complex=False).count()
        numbers.append(simplex)

        # open, closed, and total complex tokens
        all_complex = total - simplex
        closed = data.filter(Token.gold_base.contains('=')).count()
        numbers.append(all_complex)
        numbers.append(all_complex - closed)
        numbers.append(closed)

        return numbers


# -----------------------------------------------------------------------------

if __name__ == '__main__':
    manager.run()

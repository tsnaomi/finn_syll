# coding=utf-8

# standard library
import re

from datetime import datetime
from functools import wraps
from math import ceil

# installed
from flask import (
    abort,
    flash,
    Flask,
    redirect,
    render_template,
    request,
    session,
    url_for,
    )
from flaskext.markdown import Markdown
from flask.ext.migrate import Migrate, MigrateCommand
from flask.ext.seasurf import SeaSurf
from flask.ext.sqlalchemy import SQLAlchemy
from flask.ext.script import Manager
from flask.ext.bcrypt import Bcrypt
from sqlalchemy import or_
from sqlalchemy.ext.hybrid import hybrid_property
from werkzeug.exceptions import BadRequestKeyError

# local
from syllabifier import FinnSyll

app = Flask(__name__, static_folder='_static', template_folder='_templates')
app.config.from_pyfile('config.py')

db = SQLAlchemy(app)
migrate = Migrate(app, db)
manager = Manager(app)
manager.add_command('db', MigrateCommand)

# To mirate database:
#     python app.py db migrate
#     python app.py db upgrade

csrf = SeaSurf(app)
flask_bcrypt = Bcrypt(app)
markdown = Markdown(app)


# FinnSyll Models -------------------------------------------------------------

class Linguist(db.Model):
    __tablename__ = 'Linguist'

    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(40), unique=True, nullable=False)
    password = db.Column(db.String(80), nullable=False)
    is_admin = db.Column(db.Boolean, default=False)

    def __init__(self, username, password):
        self.username = username
        self.password = flask_bcrypt.generate_password_hash(password)

    def __repr__(self):
        return self.username

    def __unicode__(self):
        return self.__repr__()

    def update_password(self, password):
        '''Update the linguist's password.'''
        self.password = flask_bcrypt.generate_password_hash(password)
        db.session.commit()


class Token(db.Model):
    __tablename__ = 'Token'

    id = db.Column(db.Integer, primary_key=True)

    # a boolean indicating if this word appears in the Aamulehti newspaper
    # corpus
    is_aamulehti = db.Column(db.Boolean, default=False)

    # a boolean indicating if this word appears in the Gutenberg poetry
    is_gutenberg = db.Column(db.Boolean, default=False)

    # the word's orthography -- if pulled from the Aamulehti-1999 coprus, it
    # preserves how the word was capitalized when we first encountered it;
    # if pulled from the Gutenberg poetry, it is lowercase
    orth = db.Column(db.String(80, convert_unicode=True), nullable=False)

    # the word's orthography in lowercase, with compound boundaries delimited;
    # generated by Kati, revised by Arto
    gold_base = db.Column(db.String(80, convert_unicode=True), nullable=True)

    # the original "gold base": the word's orthography in lowercase, with
    # compound boundaries delimited; generated by Kati
    _gold_base = db.Column(db.String(80, convert_unicode=True), nullable=True)

    # the word's orthography in lowercase, with boundaries delimited; generated
    # by the compound segmenter
    test_base = db.Column(db.String(80, convert_unicode=True), nullable=True)

    # the word's lemma/citation form -- nominative singular for nouns and first
    # infinitive for verbs (obtained from Aamulehti)
    lemma = db.Column(db.String(80, convert_unicode=True), default='')

    # an enum indicating whether the word is in the training, dev, or test set
    data = db.Column(db.Enum('train', 'dev', 'test', name='DATA'))

    # an integer indicating to which fold the word belongs in cross-validation
    fold = db.Column(db.Integer, default=0)

    # rules applied in test syllabifications ----------------------------------

    rules1 = db.Column(db.String(80, convert_unicode=True), default='')

    rules2 = db.Column(db.String(80, convert_unicode=True), default='')

    rules3 = db.Column(db.String(80, convert_unicode=True), default='')

    rules4 = db.Column(db.String(80, convert_unicode=True), default='')

    rules5 = db.Column(db.String(80, convert_unicode=True), default='')

    rules6 = db.Column(db.String(80, convert_unicode=True), default='')

    rules7 = db.Column(db.String(80, convert_unicode=True), default='')

    rules8 = db.Column(db.String(80, convert_unicode=True), default='')

    rules9 = db.Column(db.String(80, convert_unicode=True), default='')

    rules10 = db.Column(db.String(80, convert_unicode=True), default='')

    rules11 = db.Column(db.String(80, convert_unicode=True), default='')

    rules12 = db.Column(db.String(80, convert_unicode=True), default='')

    rules13 = db.Column(db.String(80, convert_unicode=True), default='')

    rules14 = db.Column(db.String(80, convert_unicode=True), default='')

    rules15 = db.Column(db.String(80, convert_unicode=True), default='')

    rules16 = db.Column(db.String(80, convert_unicode=True), default='')

    # test syllabifications ---------------------------------------------------

    test_syll1 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll2 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll3 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll4 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll5 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll6 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll7 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll8 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll9 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll10 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll11 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll12 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll13 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll14 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll15 = db.Column(db.String(80, convert_unicode=True), default='')

    test_syll16 = db.Column(db.String(80, convert_unicode=True), default='')

    # correct syllabifications (hand-verified) --------------------------------

    syll1 = db.Column(db.String(80, convert_unicode=True), default='')

    syll2 = db.Column(db.String(80, convert_unicode=True), default='')

    syll3 = db.Column(db.String(80, convert_unicode=True), default='')

    syll4 = db.Column(db.String(80, convert_unicode=True), default='')

    syll5 = db.Column(db.String(80, convert_unicode=True), default='')

    syll6 = db.Column(db.String(80, convert_unicode=True), default='')

    syll7 = db.Column(db.String(80, convert_unicode=True), default='')

    syll8 = db.Column(db.String(80, convert_unicode=True), default='')

    syll9 = db.Column(db.String(80, convert_unicode=True), default='')

    syll10 = db.Column(db.String(80, convert_unicode=True), default='')

    syll11 = db.Column(db.String(80, convert_unicode=True), default='')

    syll12 = db.Column(db.String(80, convert_unicode=True), default='')

    syll13 = db.Column(db.String(80, convert_unicode=True), default='')

    syll14 = db.Column(db.String(80, convert_unicode=True), default='')

    syll15 = db.Column(db.String(80, convert_unicode=True), default='')

    syll16 = db.Column(db.String(80, convert_unicode=True), default='')

    # -------------------------------------------------------------------------

    # the word's part-of-speech
    pos = db.Column(db.String(80, convert_unicode=True), default='')

    # the word's morpho-syntactic description
    msd = db.Column(db.String(80, convert_unicode=True), default='')

    # the word's frequency in the Aamulehti-1999 corpus
    freq = db.Column(db.Integer, default=0)

    # a boolean indicating if the word is marked as a compound by Arto
    # (outdated)
    is_compound = db.Column(db.Boolean, default=False)

    # a boolean indicating if the word is marked as a compound by an annotator
    # (i.e., if gold_base contains a space, hyphen, or equal sign)
    is_complex = db.Column(db.Boolean, default=None)

    # a boolean indicating if the word is a stopword -- only if the word's
    # syllabification is lexically marked
    is_stopword = db.Column(db.Boolean, default=False)

    # a boolean indicating if the word is likely a non-nativized loanword;
    # detected with phon.is_foreign(orth)
    is_loanword = db.Column(db.Boolean, default=False)

    # a boolean indicating if the syllabifier has correclt syllabified the word
    is_gold = db.Column(db.Boolean, default=None)

    # a note field to jot down notes about the word
    note = db.Column(db.Text, default='')

    # a temporary boolean to indicate whether Arto had verified the token prior
    # to updating the database to accommodate variation in test syllabifcations
    # (this is likely safe to delete now)
    verified = db.Column(db.Boolean, default=False)

    # a one-to-many relationship with the Variant table (many Variants per
    # Token)
    variants = db.relationship(
        'Variant',
        backref='_token',
        lazy='dynamic',
        )

    # annotation helper attributes --------------------------------------------

    # a boolean indicating if the annotator requires context for the word
    needs_context = db.Column(db.Boolean, default=False)

    # an excerpt from the Aamulehti corpus containing the word
    context = db.Column(db.Text, default='')

    # -------------------------------------------------------------------------

    __mapper_args__ = {
        'order_by': [is_gold, is_complex, freq.desc()],
        }

    def __init__(self, orth, **kwargs):
        self.orth = orth

        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

        self.split()
        self.syllabify()

    def __repr__(self):
        return self.orth

    def __unicode__(self):
        return self.__repr__()

    def readable_lemma(self):
        '''Return a readable form of the lemma.'''
        return self.lemma.replace('_', ' ').lower()

    def is_lemma(self):
        '''Return True if the word is in its citation form, else False.'''
        return self.orth.lower() == self.readable_lemma().lower()

    def get_sylls_in_lemma():
        '''Return the number of syllables in the token's lemma.

        If the lemma contains variant syllabifications, return the number of
        syllables in the most preferred variant.
        '''
        pass

    def get_lemma_vowels():
        '''Return the weights and vowel quality for the token's lemma.'''
        pass

    # Syllabification methods -------------------------------------------------

    def split(self):
        '''Programmatically split Token.orth into any constituent words.'''
        self.test_base = FinnSyll.split(self.orth.lower())

    def syllabify(self):
        '''Programmatically syllabify Token.orth.'''
        syllabifications = list(FinnSyll.syllabify(self.orth.lower()))

        n = 16 - len(syllabifications)
        syllabifications += [('', '') for i in range(n)]

        for i, (test_syll, rules) in enumerate(syllabifications, start=1):
            rules = rules.translate(None, 'abcdefg')

            setattr(self, 'test_syll' + str(i), test_syll)
            setattr(self, 'rules' + str(i), rules)

        if self.syll1:
            self.update_gold()

    def update_gold(self):
        '''Token.is_gold is True iff there is perfect precision and recall.'''
        self.is_gold = self.sylls() == self.test_sylls()

    def test_sylls(self):
        '''Return a set of all of the Token's test syllabifications.'''
        test_sylls = [getattr(self, 'test_syll%s' % n) for n in range(1, 9)]
        test_sylls = set(filter(None, test_sylls))

        return test_sylls

    def sylls(self):
        '''Return a set of all of the Token's correct syllabifications.'''
        sylls = [getattr(self, 'syll%s' % n) for n in range(1, 9)]
        sylls = set(filter(None, sylls))

        return sylls

    def correct(self, **kwargs):
        '''Save new attributes to the Token and update its gold status.'''
        for attr, value in kwargs.iteritems():
            setattr(self, attr, value)

        self.update_gold()

    # Compound properties -----------------------------------------------------

    @hybrid_property
    def is_split(self):
        '''A boolean indicating if the Token is predicted to be a compound.'''
        return '=' in self.test_base

    @is_split.expression
    def is_split(cls):
        '''A boolean indicating if the Token is predicted to be a compound.'''
        return cls.test_base.contains('=')

    @hybrid_property
    def is_bad_split(self):
        '''A boolean indicating if the Token was split improperly.'''
        return self.gold_base != self.test_base

    @is_bad_split.expression
    def is_bad_split(cls):
        '''A boolean indicating if the Token was split improperly.'''
        return cls.gold_base != cls.test_base

    # Variation properties ----------------------------------------------------

    @hybrid_property
    def is_ambiguous(self):
        '''A boolean indicating if the Token exhibits T4 variation.'''
        return bool(self.test_syll2)

    @is_ambiguous.expression
    def is_ambiguous(cls):
        '''A boolean indicating if the Token exhibits T4 variation.'''
        return cls.test_syll2 != ''

    # Evaluation properties ---------------------------------------------------

    @property
    def p_r(self):
        '''A string repr of the Token's precision and recall (P / R).'''
        return '%s / %s' % (round(self.precision, 2), round(self.recall, 2))

    @property
    def precision(self):
        '''See https://en.wikipedia.org/wiki/Precision_and_recall#Precision.'''
        try:
            return round(
                len(self.test_sylls().intersection(self.sylls())) * 1.0 /
                len(self.test_sylls()),
                2)

        except ZeroDivisionError:
            return 0.0

    @property
    def recall(self):
        '''See https://en.wikipedia.org/wiki/Precision_and_recall#Recall.'''
        try:
            return round(
                len(self.test_sylls().intersection(self.sylls())) * 1.0 /
                len(self.sylls()),
                2)

        except ZeroDivisionError:
            return 0.0

    @property
    def f1(self):
        '''See https://en.wikipedia.org/wiki/F1_score.'''
        p = self.precision
        r = self.recall

        try:
            return 2.0 * (p * r) / (p + r)

        except ZeroDivisionError:
            return 0.0


class Document(db.Model):
    __tablename__ = 'Document'

    id = db.Column(db.Integer, primary_key=True)

    # the name of the xml file in the Aamulehti-1999 corpus
    filename = db.Column(db.Text, unique=True)

    # a boolean indicating if all of the document's words have been reviewed
    reviewed = db.Column(db.Boolean, default=False)

    # the text as a tokenized list, incl. Token IDs and punctuation strings
    tokenized_text = db.Column(db.PickleType)

    # a list of IDs for each word as they appear in the text
    tokens = db.Column(db.PickleType)

    # number of unique Tokens that appear in the text
    unique_count = db.Column(db.Integer)

    def __init__(self, filename, tokenized_text, tokens):
        self.filename = filename
        self.tokenized_text = tokenized_text
        self.tokens = tokens
        self.unique_count = len(tokens)

    def __repr__(self):
        return self.filename

    def __unicode__(self):
        return self.__repr__()

    def query_document(self):
        '''Return a list of Tokens and puncts as they appear in the text.'''
        tokens = {t.id: t for t in self.get_tokens()}
        doc = [tokens.get(t, t) for t in self.tokenized_text]

        return doc

    def get_tokens(self):
        '''Return a list of the Tokens that appear in the text.'''
        return db.session.query(Token).filter(Token.id.in_(self.tokens)).all()

    def verify_all_unverified_tokens(self):
        '''For all of the text's unverified Tokens, set syll equal to test_syll.

        This function is intended for when all uverified Tokens have been
        correctly syllabified in test_syll. Proceed with caution.
        '''
        tokens = self.get_tokens()

        for token in tokens:
            if token.is_gold is None:
                token.correct(syll=token.test_syll)

        self.reviewed = True
        db.session.commit()

    def update_review(self):
        '''Set reviewed to True if all of the Tokens have been verified.'''
        tokens = self.get_tokens()
        unverified_count = 0

        for t in tokens:
            if t.is_gold is None:
                unverified_count += 1
                break

        # if there are no unverified tokens but the document isn't marked as
        # reviewed, mark the document as reviewed; this would be the case if
        # all of the documents's tokens were verified in previous documents
        if unverified_count == 0:
            self.reviewed = True


class Performance(db.Model):
    __tablename__ = 'Performance'
    id = db.Column(db.Integer, primary_key=True)
    with_loanwords = db.Column(db.Boolean, default=False)
    p = db.Column(db.Float)
    r = db.Column(db.Float)
    f1 = db.Column(db.Float)
    total = db.Column(db.Integer)
    verified = db.Column(db.Integer)
    correct = db.Column(db.Integer)
    simp_verified = db.Column(db.Integer)
    simp_correct = db.Column(db.Integer)
    comp_verified = db.Column(db.Integer)
    comp_correct = db.Column(db.Integer)

    def __init__(self,  **kwargs):
        self.total = 991730  # Token.query.filter_by(is_aamulehti=True).count()
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return '%s/%s (%s)' % (self.p, self.r, self.acc)

    def __unicode__(self):
        return self.__repr__()

    @property
    def acc(self):
        '''Return total accuracy.'''
        return (float(self.correct) / self.verified) * 100

    @property
    def simplex_acc(self):
        '''Return simplex accuracy.'''
        return (float(self.simp_correct) / self.simp_verified) * 100

    @property
    def complex_acc(self):
        '''Return complex accuracy.'''
        return (float(self.comp_correct) / self.comp_verified) * 100


# Poetry Models ---------------------------------------------------------------

class Poet(db.Model):
    __tablename__ = 'Poet'

    id = db.Column(db.Integer, primary_key=True)

    # an enum indicating the poet's surname
    surname = db.Column(
        db.Enum(
            u'Erkko',        # J. H. Erkko
            u'Hellaakoski',  # Aaro Hellaakoski
            u'Kaatra',       # Kössi Kaatra
            u'Kailas',       # Uuno Kailas
            u'Koskenniemi',  # V. A. Koskenniemi
            u'Kramsu',       # Kaarlo Kramsu
            u'Leino',        # Eino Leino
            u'Lönnrot',      # Elias Lönnrot
            u'Siljo',        # Juhani Siljo
            u'Homeros',        # Homer
            name='surname',
            convert_unicode=True,
            ),
        unique=True,
        )

    # a one-to-many relationship with Book: many Books per Poet
    books = db.relationship(
        'Book',
        backref='_poet',
        lazy='dynamic',
        )

    # a one-to-many relationship with VV: many VV sequences per Poet
    sequences = db.relationship(
        'VV',
        backref='_poet',  # RENAME?
        lazy='dynamic',
        )

    def __init__(self, **kwargs):
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return self.surname

    def __unicode__(self):
        return self.__repr__()


class Book(db.Model):
    __tablename__ = 'Book'  # Book of Poetry

    id = db.Column(db.Integer, primary_key=True)

    # the title of the book of poetry
    title = db.Column(db.String(80, convert_unicode=True), default='')

    # a one-to-many relationship with Poet: many Books per Poet
    poet_id = db.Column(db.Integer, db.ForeignKey('Poet.id'))

    # a one-to-many relationship with Section: many Sections per Book
    sections = db.relationship(
        'Section',
        backref='_book',
        lazy='dynamic',
        )

    # a one-to-many relationship with Poet: many VV sequences per Book
    sequences = db.relationship(
        'VV',
        backref='_book',
        lazy='dynamic',
        )

    def __init__(self, **kwargs):
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return '%s by %s' % (self.title, self._poet.surname)

    def __unicode__(self):
        return self.__repr__()


class Section(db.Model):
    __tablename__ = 'Section'  # Book of Poetry

    id = db.Column(db.Integer, primary_key=True)

    # a one-to-many relationship with Section: many sections per book
    book_id = db.Column(db.Integer, db.ForeignKey('Book.id'))

    # a number indicating the section of the book of poetry
    section = db.Column(db.Integer, default=1)

    # the poem as a tokenized lists, incl. Variant IDs and strings of words
    text = db.Column(db.PickleType)

    # the status of the section's review
    status = db.Column(db.Enum(
        u'in-progress',
        u'complete',
        name='status',
        convert_unicode=True,
        ))

    # a one-to-many relationship with Variant: many Variants per Section
    variants = db.relationship(
        'Variant',
        backref='_section',
        lazy='dynamic',
        )

    def __init__(self, **kwargs):
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return '%s by %s (Section %s)' % (
            self._book.title,
            self._book.VV._variant._section.text_poet.surname,
            self.section,
            )

    def __unicode__(self):
        return self.__repr__()

    def update_status(self):
        '''Update the section's review status.'''
        verified = (v.verified for v in self.variants)

        if any(verified):
            self.status = 'complete' if all(verified) else 'in-progress'

    def compose(self):
        '''Return Variants and words in the section's text (for frontend).'''
        variants = {v.id: v for v in self.variants}
        text = [variants.get(w, w) for w in self.text]

        return text


class Variant(db.Model):
    __tablename__ = 'Variant'

    id = db.Column(db.Integer, primary_key=True)

    # a one-to-many relationship: many Variants per Token
    token_id = db.Column(db.Integer, db.ForeignKey('Token.id'))

    # a one-to-many relationship: many Variants per Section
    section_id = db.Column(db.Integer, db.ForeignKey('Section.id'))

    # a one-to-many relationship: many VV sequences per Variant
    sequences = db.relationship(
        'VV',
        backref='_variant',
        lazy='dynamic',
        )

    def __init__(self, **kwargs):
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return 'Variant %s' % self.id

    def __unicode__(self):
        return self.__repr__()

    @property
    def orth(self):
        '''Return the lowercase orth of the variant.'''
        return self._token.orth.lower()

    @property
    def verified(self):
        '''A boolean indicating if this Variation has been hand-verified.'''
        return all(seq.verified for seq in self.sequences)


class VV(db.Model):
    __tablename__ = 'VV'

    id = db.Column(db.Integer, primary_key=True)

    # a one-to-many relationship with Poet: many VV sequences per Poet
    poet_id = db.Column(db.Integer, db.ForeignKey('Poet.id'))

    # a one-to-many relationship with Poet: many VV sequences per Book
    book_id = db.Column(db.Integer, db.ForeignKey('Book.id'))

    # a one-to-many relationship with Variant: many VV sequences per Variant
    variant_id = db.Column(db.Integer, db.ForeignKey('Variant.id'))

    # the u- or y-final VV sequence
    sequence = db.Column(db.String(10, convert_unicode=True), default='')

    # the starting index of the VV sequence
    index = db.Column(db.Integer, default=0)

    # the line in which the VV sequence appears
    line = db.Column(db.String(140, convert_unicode=True), default='')

    # the html representation of the related token, emboldening the sequence
    html = db.Column(db.String(80, convert_unicode=True), default='')

    # a note field to jot down notes about the sequence
    note = db.Column(db.Text, default='')

    # a boolean indicating if the sequence's split and scansion have been
    # hand-verified
    verified = db.Column(db.Boolean, default=False)

    # a boolean indicating if the sequence appears in a heavy syllable
    is_heavy = db.Column(db.Boolean, default=False)

    # a boolean indicating if the sequence receives primary stress
    is_stressed = db.Column(db.Boolean, default=False)

    # an enum indicating if this sequence splits or joins
    split = db.Column(db.Enum(
        'split',
        'join',
        'unknown',
        name='split',
        ))

    # an enum indicating the scansion of this sequence
    scansion = db.Column(db.Enum(
        'S',        # strong
        'W',        # weak
        'SW',       # strong-weak
        'WS',       # weak-strong
        'SS',       # strong-strong
        'WW',       # weak-weak
        'unknown',
        name='scansion',
        ))

    def __init__(self, **kwargs):
        for attr, value in kwargs.iteritems():
            if hasattr(self, attr):
                setattr(self, attr, value)

    def __repr__(self):
        return self.sequence

    def __unicode__(self):
        return self.__repr__()

    @property
    def orth(self):
        '''Return the lowercase orth of the Sequence's variant.'''
        return self._variant.orth

    def correct(self, split=None, scansion=None, note=''):
        '''Save new attributes to the Sequence.'''
        self.split = split
        self.scansion = scansion
        self.note = note

        if split and scansion:
            self.verified = True

        self._variant._section.update_status()


# Database functions ----------------------------------------------------------

def find_token(orth):
    '''Retrieve a token by its orthography.'''
    try:
        # ilike queries are case insensitive
        token = Token.query.filter(Token.orth.ilike(orth)).first()
        return token

    except KeyError:
        return None


def adjust(func):
    '''Adjust tokens by applying func to each token.'''
    count = Token.query.count()
    start = 0
    end = x = 1000

    while start + x < count:
        for token in Token.query.order_by(Token.id).slice(start, end):
            func(token)

        db.session.commit()
        start = end
        end += x

    for token in Token.query.order_by(Token.id).slice(start, count):
        func(token)

    db.session.commit()


@manager.command
def split_compounds():
    '''Split all tokens.'''
    print 'Splitting compounds... ' + datetime.utcnow().strftime('%I:%M')

    adjust(func=lambda t: t.split())

    print 'Splitting complete. ' + datetime.utcnow().strftime('%I:%M')


@manager.command
def syllabify_tokens():
    '''Syllabify all tokens.'''
    print 'Syllabifying... ' + datetime.utcnow().strftime('%I:%M')

    adjust(func=lambda t: t.syllabify())

    print 'Syllabifications complete. ' + datetime.utcnow().strftime('%I:%M')

    # calculate average precision, recall, f1, and accuracy
    update_performance()


@manager.command
def update_performance():
    '''Calculate average precision, recall, f1, and accuracy.'''
    for with_loanwords in (True, False):
        P = Performance.query.filter_by(with_loanwords=with_loanwords).first()

        calculate = lambda t: round(float(sum(t)) / P.verified, 4)

        verified_tokens = get_gold_tokens()

        if not with_loanwords:
            verified_tokens = verified_tokens.filter_by(is_loanword=False)

        correct_tokens = verified_tokens.filter_by(is_gold=True)

        P.verified = verified_tokens.count()
        P.correct = correct_tokens.count()

        P.simp_verified = verified_tokens.filter_by(is_complex=False).count()
        P.simp_correct = correct_tokens.filter_by(is_complex=False).count()

        P.comp_verified = verified_tokens.filter_by(is_complex=True).count()
        P.comp_correct = correct_tokens.filter_by(is_complex=True).count()

        P.p = calculate([t.precision for t in verified_tokens])
        P.r = calculate([t.recall for t in verified_tokens])
        P.f1 = calculate([t.f1 for t in verified_tokens])

    db.session.commit()


# Datasets --------------------------------------------------------------------

def training_set():
    '''Return training tokens.'''
    return Token.query.filter_by(data='train')


def dev_set():
    '''Return development/validation tokens.'''
    return Token.query.filter_by(data='dev')


def test_set():
    '''Return test/evaluation tokens.'''
    return Token.query.filter_by(data='test')


def full_training_set():
    '''Return training and validation tokens.'''
    return Token.query.filter(or_(Token.data == 'train', Token.data == 'dev'))


def training_test_set():
    '''Returning training and test tokens.'''
    return Token.query.filter(or_(Token.data == 'train', Token.data == 'test'))


def all_data():
    '''Return training, validation, and test tokens.'''
    return Token.query.filter(Token.data.isnot(None))


def get_fold(fold):
    '''Return all of the training/test tokens in the designated fold.'''
    return all_data().filter_by(fold=fold)


def exclude_fold(fold):
    '''Return all training/test tokens except those in the designated fold.'''
    return all_data().filter(Token.fold != fold)


# Basic queries ---------------------------------------------------------------

def get_gold_tokens(tokens=Token.query):
    '''Return all verified tokens -- good or bad.'''
    return tokens.filter(Token.is_gold.isnot(None))


def get_bad_tokens():
    '''Return all of the tokens that are incorrectly syllabified.'''
    return Token.query.filter_by(is_gold=False)


def get_good_tokens():
    '''Return all of the tokens that are correctly syllabified.'''
    return Token.query.filter_by(is_gold=True).order_by(Token.lemma)


def get_unverified_tokens():
    '''Return tokens with uncertain syllabifications.'''
    return Token.query.filter_by(is_aamulehti=True, is_gold=None)


def get_variation():
    '''Return tokens with alternative test or gold syllabifications.'''
    return Token.query.filter_by(is_aamulehti=True).filter(Token.is_ambiguous)


def get_loanwords():
    '''Return non-nativized or flagged loanwords.'''
    return get_gold_tokens().filter(or_(
        Token.is_loanword == True),  # noqa non-nativized loanwords
        Token.note.contains('[foreign')  # expicitly marked as foreign
        )


def get_consonant_gradation():
    '''Return tokens that exhibit consonant gradation.'''
    return get_gold_tokens().filter(Token.note.contains('[k-deletion'))


def get_notes():
    '''Return all of the tokens that contain notes.'''
    return get_gold_tokens().filter(Token.note != '').order_by(Token.note)


# View helpers ----------------------------------------------------------------

@app.before_request
def renew_session():
    # Forgot why I did this... but I think it's important
    session.modified = True


def login_required(x):
    # View decorator requiring users to be authenticated to access the view
    @wraps(x)
    def decorator(*args, **kwargs):
        if session.get('current_user'):

            if session.get('is_admin'):
                return x(*args, **kwargs)

            if x.func_name == 'main_view':
                return redirect(url_for('annotation_view'))

            abort(404)

        return redirect(url_for('login_view'))

    return decorator


# @app.context_processor
def serve_docs():
    # Serve Aamulehti documents to all views
    docs = Document.query.filter_by(reviewed=False)
    docs = docs.order_by(Document.unique_count).limit(10)

    return dict(docs=docs)


def apply_form(http_form, commit=True):
    # Apply changes to Token instance based on POST request
    try:
        token = Token.query.get(http_form['id'])
        syll1 = http_form['syll1']
        syll2 = http_form.get('syll2', '')
        syll3 = http_form.get('syll3', '')
        syll4 = http_form.get('syll4', '')
        note = http_form.get('note', '')

        token.correct(
            syll1=syll1,
            syll2=syll2,
            syll3=syll3,
            syll4=syll4,
            note=note,
            )

        if commit:
            db.session.commit()

    except (AttributeError, KeyError, LookupError):
        pass


def apply_bulk_form(http_form):
    # Apply changes to multiple Token instances based on POST request
    forms = {k: {} for k in range(1, 41)}

    for i in range(1, 41):
        for attr in ['id', 'syll1', 'syll2', 'syll3', 'syll4', 'note']:
            try:
                forms[i][attr] = http_form['%s_%s' % (attr, i)]

            except BadRequestKeyError:
                pass

    for form in forms.itervalues():
        apply_form(form, commit=False)

    db.session.commit()


def perform_search(find, search_type):  # noqa
    '''Perform query from search box.'''
    try:
        # strip periods
        find = find.strip().translate({ord('.'): None, })

        # extract query
        query = re.match(
            r'^([a-zäöÄÖ=]*)(?:$|[^\w]+)',
            find.encode('utf-8'),
            re.IGNORECASE,
            ).group(1)

    except AttributeError:
        query = ''

    # extract rules
    rules = re.findall(r'(T[abcde0-9]+)', find)

    if query or rules:
        # if an asterisk is present, only search amongst gold tokens
        if '*' in find:
            results = get_gold_tokens()

        # otherwise, still limit search to Aamulehti tokens
        else:
            results = Token.query.filter_by(is_aamulehti=True)

        # case-insensitive word-boundary search
        if search_type == 'contains' and re.match(r'(^=.*|.*=$)', query):
            query = query.decode('utf-8').lower()

            if query.startswith('=') and len(query) > 1:
                pattern = r'(^|.*=)' + query[1:] + r'.*'
                results = results.filter(Token.gold_base.op('~')(pattern))

            else:
                results = results.filter(Token.gold_base.contains(query))

        # case-insensitive search
        else:
            if search_type == 'contains':
                query = '%' + query + '%'

            results = results.filter(Token.orth.ilike(query))

    elif '*' == find:
        # return gold tokens
        results = get_gold_tokens().order_by(Token.freq)

    else:
        # don't return anything if it is an invalid search
        results = Token.query.filter(0 == 1)

    # filter results by rules
    for r in rules:
        results = results.filter(or_(
            getattr(Token, 'rules%s' % n).contains(r) for n in range(1, 17)
        ))

    return results


# Views -----------------------------------------------------------------------

@app.route('/', methods=['GET', 'POST'])
@login_required
def main_view():
    '''List statistics on the syllabifier's performance.'''
    P1 = Performance.query.filter_by(with_loanwords=False).first()
    P2 = Performance.query.filter_by(with_loanwords=True).first()

    return render_template('main.html', kw='main', P1=P1, P2=P2)


@app.route('/syllabify', methods=['GET', 'POST'])
@login_required
def syllabify_view():
    '''Allow users to specify an input to syllabify.'''
    word, results = '', []

    if request.method == 'POST' and request.form.get('word'):
        word = request.form['word']
        results = FinnSyll.syllabify(word)

    return render_template(
        'syllabify.html',
        kw='syllabify',
        word=word,
        results=results,
        )


@app.route('/rules', methods=['GET', ])
@login_required
def rules_view():
    '''List syllabification rules.'''
    return render_template('rules.html', kw='rules')


@app.route('/doc/<id>', methods=['GET', 'POST'])
@login_required
def doc_view(id):
    '''Present detail view of specified doc, composed of editable Tokens.'''
    if request.method == 'POST':
        apply_form(request.form)

    doc = Document.query.get_or_404(id)
    TEXT = doc.query_document()

    scroll = request.form.get('scroll', None)

    return render_template(
        'doc.html',
        doc=doc,
        TEXT=TEXT,
        kw='doc',
        scroll=scroll,
        )


@app.route('/approve/approve/approve/doc/<id>', methods=['POST', ])
@login_required
def approve_doc_view(id):
    '''For all of the doc's unverified Tokens, set syll equal to test_syll.'''
    doc = Document.query.get_or_404(id)
    doc.verify_all_unverified_tokens()

    return redirect(url_for('doc_view', id=id))


@app.route('/search', methods=['GET', 'POST'])
@login_required
def search_view():
    '''Search for tokens by word and/or citation form.'''
    results, find, count, search_type = None, None, None, None

    if request.method == 'POST':
        search_type = request.form.get('search')

        # save any revisions to search result tokens
        if request.form.get('syll1'):
            apply_form(request.form)

        # extract search phrase
        find = request.form.get('query')

        if find:
            # collect search results
            results = perform_search(find, search_type)
            count = results.count()
            results = results.slice(0, 200) if results else None

    return render_template(
        'search.html',
        kw='search',
        find=find,
        search_type=search_type,
        results=results,
        count=count,
        )


@app.route('/<kw>', defaults={'page': 1}, methods=['GET', 'POST'])
@app.route('/<kw>/page/<int:page>', methods=['GET', 'POST'])
@login_required
def token_view(kw, page):
    '''List all keyword-relevant Tokens and process corrections.'''
    display_note, description = True, ''

    if request.method == 'POST':
        apply_form(request.form)

    if kw == 'bad':
        # retrieve all mis-syllabified tokens
        tokens = get_bad_tokens().order_by(
            Token.is_bad_split,
            Token.note.desc(),
            )
        description = (
            'This page lists words that have <i>imperfect</i> precision and '
            'recall'
            )

    elif kw == 'notes':
        # retrieve tokens that contain any notes
        tokens = get_notes()
        description = 'This page lists words containing <i>notes</i>.'

    else:
        abort(404)

    count = format(tokens.count(), ',d')
    tokens, pagination = paginate(page, tokens)

    return render_template(
        'tokens.html',
        tokens=tokens,
        display_note=display_note,
        description=description,
        kw=kw,
        pagination=pagination,
        count=count,
        )


@app.route('/enter', methods=['GET', 'POST'])
def login_view():
    '''Sign in current user.'''
    if session.get('current_user'):
        return redirect(url_for('main_view'))

    if request.method == 'POST':
        username = request.form['username']
        linguist = Linguist.query.filter_by(username=username).first()

        if linguist is None or not flask_bcrypt.check_password_hash(
                linguist.password,
                request.form['password']
                ):
            flash('Invalid username and/or password.')

        else:
            session['current_user'] = linguist.username
            session['is_admin'] = linguist.is_admin
            return redirect(url_for('main_view'))

    return render_template('enter.html')


@app.route('/leave')
def logout_view():
    '''Sign out current user.'''
    session.pop('current_user', None)
    session.pop('is_admin', None)

    return redirect(url_for('main_view'))


# Poems -----------------------------------------------------------------------


@app.route('/poems', methods=['GET', ])
@login_required
def poems_view():
    '''Return the books of poetry to form a Table of Contents.'''
    sections = (
        Section.query.join(Book).join(Poet)
        .order_by(Poet.surname, Section.id)
        )

    return render_template('poems.html', sections=sections, kw='poems')


@app.route('/poems/<id>', methods=['GET', ])
@login_required
def poem_view(id):
    '''Present a detail view of the book excerpt, composed of editable VV.'''
    section = Section.query.get_or_404(id)
    text = section.compose()

    return render_template('poem.html', section=section, text=text, kw='poem')


# an inelegant view to make the frontend faster
@app.route('/poems/edit-sequence', methods=['POST', ])
@login_required
def poem_edit_view():
    '''Update VV annotations.'''
    n = 2 if request.form.get('id_2') else 1
    forms = {k: {} for k in range(1, n + 1)}
    attrs = ['id', 'split', 'scansion', 'note']

    for i in range(1, n + 1):
        for attr in attrs:
            try:
                forms[i][attr] = request.form.get('%s_%s' % (attr, i))

            except BadRequestKeyError as e:
                print '********', e

    for form in forms.itervalues():
        seq = VV.query.get(form['id'])
        seq.correct(
            split=form['split'],
            scansion=form['scansion'],
            note=form['note'],
            )

    db.session.commit()

    variant = seq._variant

    # welp
    response = 'populatemodal(' + '%s,' * 6 % (
        str(variant.id),
        '"' + str(variant.sequences[0].id) + '"',
        '"' + variant.sequences[0].html + '|safe' + '"',
        '"' + str(variant.sequences[0].split) + '"',
        '"' + str(variant.sequences[0].scansion) + '"',
        '"' + variant.sequences[0].note + '|safe' + '"',
        )

    try:
        response += '%s,' * 5 + ');' % (
            str(variant.sequences[1].id),
            '"' + variant.sequences[1].html + '|safe' + '"',
            '"' + str(variant.sequences[1].split) + '"',
            '"' + str(variant.sequences[1].scansion) + '"',
            '"' + variant.sequences[1].note + '|safe' + '"',
            )

    except IndexError:
        response += '"",' * 5 + ');'

    response += '' if variant.verified else ' unverified'

    return response, 200


# Jinja2 ----------------------------------------------------------------------

def stat(n):
    if int(n) == float(n):
        return '{:,}'.format(n)

    if n < 1.0:
        return '{:.4f}'.format(n)

    return '{:.2f}'.format(n)


def goldclass(t):
    gold = t.is_gold
    gold = u'good' if gold else u'unverified' if gold is None else u'bad'
    compound = ' compound' if t.is_complex else ''

    return gold + compound


def variationclass(v):
    return 'variation-verified' if v.verified else 'variation-unverified'


def js_safe(s):
    s = s.replace('\r\n', '&#13;&#10;')
    s = s.replace('(', '&#40;').replace(')', '&#41;')
    s = s.replace('"', '&#34;').replace("'", '&#34;')

    return s


app.jinja_env.filters['stat'] = stat
app.jinja_env.filters['goldclass'] = goldclass
app.jinja_env.filters['variationclass'] = variationclass
app.jinja_env.filters['js_safe'] = js_safe
app.jinja_env.tests['token'] = lambda t: hasattr(t, 'syll1')
app.jinja_env.tests['variant'] = lambda v: hasattr(v, 'token_id')


# Pagination ------------------------------------------------------------------

class Pagination(object):

    def __init__(self, page, per_page, total_count):
        self.page = page
        self.per_page = per_page
        self.total_count = total_count

    @property
    def pages(self):
        return int(ceil(self.total_count / float(self.per_page)))

    @property
    def has_prev(self):
        return self.page > 1

    @property
    def has_next(self):
        return self.page < self.pages

    def iter_pages(self):
        left_edge, left_current = 2, 2
        right_edge, right_current = 2, 5

        last = 0
        for num in xrange(1, self.pages + 1):

            if num <= left_edge or (
                num > self.page - left_current - 1 and
                num < self.page + right_current
                    ) or num > self.pages - right_edge:

                if last + 1 != num:
                    yield None

                yield num

                last = num


def paginate(page, tokens, per_page=40):
    count = tokens.count()
    start = (page - 1) * per_page or 0
    end = min(start + per_page, count)

    try:
        tokens = tokens[start:end]

    except IndexError:
        if page != 1:
            abort(404)

    pagination = Pagination(page, per_page, count)

    return tokens, pagination


def url_for_other_page(page):
    args = request.view_args.copy()
    args['page'] = page

    return url_for(request.endpoint, **args)

app.jinja_env.globals['url_for_other_page'] = url_for_other_page


# -----------------------------------------------------------------------------

if __name__ == '__main__':
    manager.run()
